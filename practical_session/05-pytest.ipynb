{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Les tests\n",
    "\n",
    ":::{note} Les objectifs de cette partie\n",
    "- Savoir définir les différents types de tests.\n",
    "- Savoir utiliser pytest pour les mettre en place.\n",
    ":::\n",
    "\n",
    "Lorsque l'on écrit un programme, il est généralement constitué de plusieurs fonctions que l'on assemble afin de décrire notre algorithme permettant de nous donner la réponse à notre problème. Un programme n'est pas forcément un développement sur un temps court. On voit beaucoup de librairies scientifiques qui ont plus de dix ans. Les fonctions peuvent donc être écrites à différents moments avec des échelles de temps bien différentes. On peut par exemple ajouter une fonctionnalité à un bout de code plusieurs années après en avoir écrit le coeur. Si il est primordial d'écrire de la documentation pour comprendre ce qui est fait, il est également judicieux d'écrire des tests pour s'assurer du bon fonctionnement de notre programme.\n",
    "\n",
    "Il faut noter que certains types de développement logiciel s'appuient sur les tests ([Test Driven Development](http://fr.wikipedia.org/wiki/Test_Driven_Development)).\n",
    "\n",
    "On peut citer trois types de tests primordiaux permettant de s'assurer au mieux de l'absence de bugs dans notre programme. Un programme n'est jamais à 100% sûr.\n",
    "\n",
    "- les **tests unitaires** permettent de tester des fonctions ou des méthodes. \n",
    "\n",
    "- les **tests d'intégration** permettent de tester les interactions entre un petit nombre d'unités de programme.\n",
    "\n",
    "- les **tests du système complet** permettent de tester le programme dans sa globalité.\n",
    "\n",
    "Les tests sont donc écrits à des stades différents du développement mais ont chacun leur importance. Un seul de ces trois types de tests ne suffit pas pour tester l'intégrité du programme. Les tests unitaires et les tests d'intégration sont généralement testés avec les mêmes outils. Pour le dernier type de tests, on prendra des exemples concrets d'exécution et on testera la sortie avec une solution certifiée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Notre cas d'étude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Nous allons calculer les coefficients de la suite de Fibonacci en utilisant les coefficients binomiaux. Les Coefficients binomiaux se calculent à partir de la formule suivante\n",
    "\n",
    "$$\n",
    "\\left(\n",
    "\\begin{array}{c}\n",
    "n \\\\\n",
    "k\n",
    "\\end{array}\n",
    "\\right)=C_n^k=\\frac{n!}{k!(n-k)!} \\; \\text{pour} \\; k=0,\\cdots,n.\n",
    "$$\n",
    "\n",
    "On en déduit alors le calcul des coefficients de la suite de Fibonacci par la formule suivante\n",
    "\n",
    "$$\n",
    "\\sum_{k=0}^n\n",
    "\\left(\n",
    "\\begin{array}{c}\n",
    "n-k \\\\\n",
    "k\n",
    "\\end{array} \n",
    "\\right)\n",
    "= F(n+1).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Voici un exemple de code Python implantant cette formule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting examples/tests/fibonacci.py\n"
     ]
    }
   ],
   "source": [
    "%%file examples/tests/fibonacci.py\n",
    "import numpy as np\n",
    "\n",
    "def factorielle(n):\n",
    "    \"\"\"\n",
    "    calcul de n!\n",
    "\n",
    "    >>> factorielle(0)\n",
    "    10\n",
    "    >>> factorielle(5)\n",
    "    120\n",
    "\n",
    "    \"\"\"\n",
    "    if n==1 or n==0:\n",
    "        return 1\n",
    "    else:\n",
    "        return n*factorielle(n-1)\n",
    "\n",
    "def somme(deb, fin, f, fargs=()):\n",
    "    \"\"\"\n",
    "    calcul de\n",
    "\n",
    "    $$\n",
    "    \\sum_{k=deb}^fin f(k, *fargs)\n",
    "    $$\n",
    "\n",
    "    test d'une suite arithmetique\n",
    "    >>> somme(0, 10, lambda k:k)\n",
    "    55.0\n",
    "\n",
    "    test d'une suite geometrique\n",
    "    >>> somme(1, 8, lambda k: 2**k)\n",
    "    510.0\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    som = 0.\n",
    "    for k in range(deb, fin + 1):\n",
    "        som += f(k, *fargs)\n",
    "    return som\n",
    "\n",
    "def coef_binomial(n, k):\n",
    "    \"\"\"\n",
    "    calcul de $C_n^k$\n",
    "\n",
    "    >>> coef_binomial(4, 2)\n",
    "    6\n",
    "\n",
    "    \"\"\"\n",
    "    if k > n or k < 0:\n",
    "        return 0.\n",
    "    return factorielle(n)//(factorielle(k)*factorielle(n-k))\n",
    "\n",
    "def fibonacci(n):\n",
    "    \"\"\"\n",
    "    Renvoie la liste des n premiers termes de la suite de Fibonacci\n",
    "\n",
    "    >>> fibonacci(10)\n",
    "    [1, 1, 2, 3, 5, 8, 13, 21, 34, 55]\n",
    "\n",
    "    \"\"\"\n",
    "    def g(k, n):\n",
    "        return coef_binomial(n - k, k)\n",
    "\n",
    "    fibo = []\n",
    "    for i in range(n):\n",
    "        fibo.append(int(somme(0, i, g, fargs=(i,))))\n",
    "\n",
    "    return fibo\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import doctest\n",
    "    doctest.testmod(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "On souhaite faire les tests suivants\n",
    "\n",
    "* **tests unitaires**: tester si les fonctions factorielle et somme fonctionnent correctement.\n",
    "* **tests d'intégration**: tester si les fonctions factorielle et somme fonctionnent correctement ensemble, tester si la fonction coef_binomial fonctionne correctement.\n",
    "* **tests du système complet**: tester si la fonction fibonacci donne le bon résultat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    ":::{attention}\n",
    "Il existe différents outils en Python permettant de réaliser des tests ([https://wiki.python.org/moin/PythonTestingToolsTaxonomy](https://wiki.python.org/moin/PythonTestingToolsTaxonomy)). \n",
    "\n",
    "- doctest\n",
    "- unittest\n",
    "- nose\n",
    "- pytest\n",
    "\n",
    "Nous ne nous intéresserons ici qu'à `pytest` qui est devenu l'incontournable.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tour d'horizon de pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Quelques caractéristiques de pytest:\n",
    "\n",
    "- très simple à utiliser\n",
    "- multi plateforme\n",
    "- comprend `doctest` et `unittest`\n",
    "- modulaire\n",
    "- plein de plugins sont disponibles (par exemple [pep8](https://pypi.python.org/pypi/pytest-pep8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.11.6, pytest-7.4.3, pluggy-1.3.0 -- /Users/loic/mambaforge/envs/packaging-2023/bin/python3.11\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/loic/Formations/packaging/practical_session\n",
      "plugins: anyio-4.0.0\n",
      "collected 4 items                                                              \u001b[0m\u001b[1m\n",
      "\n",
      "examples/tests/fibonacci.py::fibonacci.coef_binomial \u001b[32mPASSED\u001b[0m\u001b[33m              [ 25%]\u001b[0m\n",
      "examples/tests/fibonacci.py::fibonacci.factorielle \u001b[31mFAILED\u001b[0m\u001b[31m                [ 50%]\u001b[0m\n",
      "examples/tests/fibonacci.py::fibonacci.fibonacci \u001b[32mPASSED\u001b[0m\u001b[31m                  [ 75%]\u001b[0m\n",
      "examples/tests/fibonacci.py::fibonacci.somme \u001b[32mPASSED\u001b[0m\u001b[31m                      [100%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m_______________________ [doctest] fibonacci.factorielle ________________________\u001b[0m\n",
      "004 \n",
      "005     calcul de n!\n",
      "006     \n",
      "007     >>> factorielle(0)\n",
      "Expected:\n",
      "    10\n",
      "Got:\n",
      "    1\n",
      "\n",
      "\u001b[1m\u001b[31m/Users/loic/Formations/packaging/practical_session/examples/tests/fibonacci.py\u001b[0m:7: DocTestFailure\n",
      "\u001b[33m=============================== warnings summary ===============================\u001b[0m\n",
      "examples/tests/fibonacci.py:19\n",
      "  /Users/loic/Formations/packaging/practical_session/examples/tests/fibonacci.py:19: DeprecationWarning: invalid escape sequence '\\s'\n",
      "    \"\"\"\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m examples/tests/fibonacci.py::\u001b[1mfibonacci.factorielle\u001b[0m\n",
      "\u001b[31m==================== \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m3 passed\u001b[0m, \u001b[33m1 warning\u001b[0m\u001b[31m in 5.36s\u001b[0m\u001b[31m ====================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pytest -v --doctest-modules examples/tests/fibonacci.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Toutes les comparaisons dans `pytest` sont basées sur `assert`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting examples/tests/test_fibo.py\n"
     ]
    }
   ],
   "source": [
    "%%file examples/tests/test_fibo.py\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"./examples/tests\")\n",
    "from fibonacci import *\n",
    "\n",
    "def test_factorielle_0():\n",
    "    assert factorielle(0) == 1\n",
    "\n",
    "def test_factorielle_5():\n",
    "    assert factorielle(5) == 120\n",
    "\n",
    "def test_somme():\n",
    "    assert somme(0, 10, lambda k:k) == 55\n",
    "\n",
    "def test_coef_binomial():\n",
    "    assert coef_binomial(4, 2) == 6\n",
    "\n",
    "def test_fibo():\n",
    "    assert fibonacci(10) == [1, 1, 2, 3, 5, 8, 13, 21, 34, 55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.11.6, pytest-7.4.3, pluggy-1.3.0 -- /Users/loic/mambaforge/envs/packaging-2023/bin/python3.11\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/loic/Formations/packaging/practical_session\n",
      "plugins: anyio-4.0.0\n",
      "collected 5 items                                                              \u001b[0m\n",
      "\n",
      "examples/tests/test_fibo.py::test_factorielle_0 \u001b[32mPASSED\u001b[0m\u001b[33m                   [ 20%]\u001b[0m\n",
      "examples/tests/test_fibo.py::test_factorielle_5 \u001b[32mPASSED\u001b[0m\u001b[33m                   [ 40%]\u001b[0m\n",
      "examples/tests/test_fibo.py::test_somme \u001b[32mPASSED\u001b[0m\u001b[33m                           [ 60%]\u001b[0m\n",
      "examples/tests/test_fibo.py::test_coef_binomial \u001b[32mPASSED\u001b[0m\u001b[33m                   [ 80%]\u001b[0m\n",
      "examples/tests/test_fibo.py::test_fibo \u001b[32mPASSED\u001b[0m\u001b[33m                            [100%]\u001b[0m\n",
      "\n",
      "\u001b[33m=============================== warnings summary ===============================\u001b[0m\n",
      "examples/tests/fibonacci.py:19\n",
      "  /Users/loic/Formations/packaging/practical_session/examples/tests/fibonacci.py:19: DeprecationWarning: invalid escape sequence '\\s'\n",
      "    \"\"\"\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[33m========================= \u001b[32m5 passed\u001b[0m, \u001b[33m\u001b[1m1 warning\u001b[0m\u001b[33m in 0.10s\u001b[0m\u001b[33m =========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pytest -vv examples/tests/test_fibo.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `skip` et `skipif`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting examples/tests/test_skip.py\n"
     ]
    }
   ],
   "source": [
    "%%file examples/tests/test_skip.py\n",
    "\n",
    "import sys\n",
    "import pytest\n",
    "\n",
    "@pytest.mark.skip(reason=\"doesn't work !!\")\n",
    "def test_skip():\n",
    "    assert True\n",
    "\n",
    "@pytest.mark.skipif(sys.version_info < (3, 6), reason=\"Python version too old\")\n",
    "def test_skipif():\n",
    "    assert True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.11.6, pytest-7.4.3, pluggy-1.3.0 -- /Users/loic/mambaforge/envs/packaging-2023/bin/python3.11\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/loic/Formations/packaging/practical_session\n",
      "plugins: anyio-4.0.0\n",
      "collected 2 items                                                              \u001b[0m\n",
      "\n",
      "examples/tests/test_skip.py::test_skip \u001b[33mSKIPPED\u001b[0m (doesn't work !!)\u001b[32m         [ 50%]\u001b[0m\n",
      "examples/tests/test_skip.py::test_skipif \u001b[32mPASSED\u001b[0m\u001b[32m                          [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m========================= \u001b[32m\u001b[1m1 passed\u001b[0m, \u001b[33m1 skipped\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[32m =========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pytest -v examples/tests/test_skip.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Ajouter un marqueur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting examples/tests/test_mark.py\n"
     ]
    }
   ],
   "source": [
    "%%file examples/tests/test_mark.py\n",
    "\n",
    "import pytest\n",
    "\n",
    "@pytest.mark.slow\n",
    "def test_slow():\n",
    "    assert True\n",
    "\n",
    "def test_not_slow():\n",
    "    assert True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.11.6, pytest-7.4.3, pluggy-1.3.0 -- /Users/loic/mambaforge/envs/packaging-2023/bin/python3.11\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/loic/Formations/packaging/practical_session\n",
      "plugins: anyio-4.0.0\n",
      "collected 2 items                                                              \u001b[0m\n",
      "\n",
      "examples/tests/test_mark.py::test_slow \u001b[32mPASSED\u001b[0m\u001b[33m                            [ 50%]\u001b[0m\n",
      "examples/tests/test_mark.py::test_not_slow \u001b[32mPASSED\u001b[0m\u001b[33m                        [100%]\u001b[0m\n",
      "\n",
      "\u001b[33m=============================== warnings summary ===============================\u001b[0m\n",
      "examples/tests/test_mark.py:4\n",
      "  /Users/loic/Formations/packaging/practical_session/examples/tests/test_mark.py:4: PytestUnknownMarkWarning: Unknown pytest.mark.slow - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n",
      "    @pytest.mark.slow\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[33m========================= \u001b[32m2 passed\u001b[0m, \u001b[33m\u001b[1m1 warning\u001b[0m\u001b[33m in 0.01s\u001b[0m\u001b[33m =========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pytest -v examples/tests/test_mark.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.11.6, pytest-7.4.3, pluggy-1.3.0 -- /Users/loic/mambaforge/envs/packaging-2023/bin/python3.11\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/loic/Formations/packaging/practical_session\n",
      "plugins: anyio-4.0.0\n",
      "collected 2 items / 1 deselected / 1 selected                                  \u001b[0m\n",
      "\n",
      "examples/tests/test_mark.py::test_slow \u001b[32mPASSED\u001b[0m\u001b[33m                            [100%]\u001b[0m\n",
      "\n",
      "\u001b[33m=============================== warnings summary ===============================\u001b[0m\n",
      "examples/tests/test_mark.py:4\n",
      "  /Users/loic/Formations/packaging/practical_session/examples/tests/test_mark.py:4: PytestUnknownMarkWarning: Unknown pytest.mark.slow - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n",
      "    @pytest.mark.slow\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[33m================== \u001b[32m1 passed\u001b[0m, \u001b[33m\u001b[1m1 deselected\u001b[0m, \u001b[33m\u001b[1m1 warning\u001b[0m\u001b[33m in 0.00s\u001b[0m\u001b[33m ==================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pytest -v -m slow examples/tests/test_mark.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\r\n",
      "platform linux -- Python 3.6.4, pytest-3.2.3, py-1.4.34, pluggy-0.4.0 -- /home/loic/miniconda3/envs/python3.6/bin/python\r\n",
      "cachedir: .cache\r\n",
      "rootdir: /home/loic/Formations/2017/python/cnrs, inifile:\r\n",
      "plugins: pylint-0.7.1, pep8-1.0.6, cov-2.5.1\r\n",
      "\u001b[1m\r\n",
      "collecting 0 items                                                              \u001b[0m\u001b[1m\r\n",
      "collecting 2 items                                                              \u001b[0m\u001b[1m\r\n",
      "collected 2 items                                                               \u001b[0m\r\n",
      "\r\n",
      "examples/tests/test_mark.py::test_not_slow \u001b[32mPASSED\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m============================== 1 tests deselected ==============================\u001b[0m\r\n",
      "\u001b[32m\u001b[1m==================== 1 passed, 1 deselected in 0.00 seconds ====================\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "! pytest -v -m \"not slow\" examples/tests/test_mark.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Capture de la sortie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting examples/tests/test_capture.py\n"
     ]
    }
   ],
   "source": [
    "%%file examples/tests/test_capture.py\n",
    "\n",
    "def test_capture():\n",
    "    print(\"coucou\")\n",
    "    assert True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.11.6, pytest-7.4.3, pluggy-1.3.0 -- /Users/loic/mambaforge/envs/packaging-2023/bin/python3.11\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/loic/Formations/packaging/practical_session\n",
      "plugins: anyio-4.0.0\n",
      "collected 1 item                                                               \u001b[0m\n",
      "\n",
      "examples/tests/test_capture.py::test_capture \u001b[32mPASSED\u001b[0m\u001b[32m                      [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.00s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pytest -v examples/tests/test_capture.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.11.6, pytest-7.4.3, pluggy-1.3.0 -- /Users/loic/mambaforge/envs/packaging-2023/bin/python3.11\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/loic/Formations/packaging/practical_session\n",
      "plugins: anyio-4.0.0\n",
      "collected 1 item                                                               \u001b[0m\n",
      "\n",
      "examples/tests/test_capture.py::test_capture coucou\n",
      "\u001b[32mPASSED\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.00s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pytest -v -s examples/tests/test_capture.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exécuter les tests par mots clés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting examples/tests/test_key.py\n"
     ]
    }
   ],
   "source": [
    "%%file examples/tests/test_key.py\n",
    "\n",
    "def test_foo_1():\n",
    "    assert True\n",
    "\n",
    "def test_foo_2():\n",
    "    assert True\n",
    "\n",
    "def test_bar_1():\n",
    "    assert True\n",
    "\n",
    "def test_bar_2():\n",
    "    assert True\n",
    "\n",
    "def test_bar_3():\n",
    "    assert True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.11.6, pytest-7.4.3, pluggy-1.3.0 -- /Users/loic/mambaforge/envs/packaging-2023/bin/python3.11\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/loic/Formations/packaging/practical_session\n",
      "plugins: anyio-4.0.0\n",
      "collected 5 items / 3 deselected / 2 selected                                  \u001b[0m\n",
      "\n",
      "examples/tests/test_key.py::test_foo_1 \u001b[32mPASSED\u001b[0m\u001b[32m                            [ 50%]\u001b[0m\n",
      "examples/tests/test_key.py::test_foo_2 \u001b[32mPASSED\u001b[0m\u001b[32m                            [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m2 passed\u001b[0m, \u001b[33m3 deselected\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[32m ========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pytest -v -k foo examples/tests/test_key.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.11.6, pytest-7.4.3, pluggy-1.3.0 -- /Users/loic/mambaforge/envs/packaging-2023/bin/python3.11\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/loic/Formations/packaging/practical_session\n",
      "plugins: anyio-4.0.0\n",
      "collected 5 items / 2 deselected / 3 selected                                  \u001b[0m\n",
      "\n",
      "examples/tests/test_key.py::test_bar_1 \u001b[32mPASSED\u001b[0m\u001b[32m                            [ 33%]\u001b[0m\n",
      "examples/tests/test_key.py::test_bar_2 \u001b[32mPASSED\u001b[0m\u001b[32m                            [ 66%]\u001b[0m\n",
      "examples/tests/test_key.py::test_bar_3 \u001b[32mPASSED\u001b[0m\u001b[32m                            [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m3 passed\u001b[0m, \u001b[33m2 deselected\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[32m ========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pytest -v -k bar examples/tests/test_key.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.11.6, pytest-7.4.3, pluggy-1.3.0 -- /Users/loic/mambaforge/envs/packaging-2023/bin/python3.11\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/loic/Formations/packaging/practical_session\n",
      "plugins: anyio-4.0.0\n",
      "collected 5 items / 3 deselected / 2 selected                                  \u001b[0m\n",
      "\n",
      "examples/tests/test_key.py::test_foo_1 \u001b[32mPASSED\u001b[0m\u001b[32m                            [ 50%]\u001b[0m\n",
      "examples/tests/test_key.py::test_foo_2 \u001b[32mPASSED\u001b[0m\u001b[32m                            [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m2 passed\u001b[0m, \u001b[33m3 deselected\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[32m ========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pytest -v -k \"not bar\" examples/tests/test_key.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `fixture`\n",
    "\n",
    "- Permet de spécifier plus facilement ce qu'il faut faire avant et après un test.\n",
    "- Peut s'appliquer à une fonction, une classe, un module ou tout le projet.\n",
    "- Une `fixture` peut appeler une autre `fixture`.\n",
    "- Une `fixture` est appelée par son nom par le test qui en a besoin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting examples/tests/test_fixture_1.py\n"
     ]
    }
   ],
   "source": [
    "%%file examples/tests/test_fixture_1.py\n",
    "\n",
    "import pytest\n",
    "\n",
    "@pytest.fixture()\n",
    "def tmpfile():\n",
    "    with open(\"tmp_fixture.txt\", \"w\") as f:\n",
    "        yield f\n",
    "\n",
    "def test_file(tmpfile):\n",
    "    tmpfile.write(\"temporary file : \" + tmpfile.name)\n",
    "    assert True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.11.6, pytest-7.4.3, pluggy-1.3.0 -- /Users/loic/mambaforge/envs/packaging-2023/bin/python3.11\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/loic/Formations/packaging/practical_session\n",
      "plugins: anyio-4.0.0\n",
      "collected 1 item                                                               \u001b[0m\n",
      "\n",
      "examples/tests/test_fixture_1.py::test_file \u001b[32mPASSED\u001b[0m\u001b[32m                       [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.00s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pytest -v examples/tests/test_fixture_1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temporary file : tmp_fixture.txt"
     ]
    }
   ],
   "source": [
    "! cat tmp_fixture.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `parametrize`\n",
    "\n",
    "Il est également possible de définir un ensemble de paramètres à tester."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting examples/tests/test_parametrize_1.py\n"
     ]
    }
   ],
   "source": [
    "%%file examples/tests/test_parametrize_1.py\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"./examples/tests\")\n",
    "import pytest\n",
    "\n",
    "from fibonacci import *\n",
    "\n",
    "@pytest.mark.parametrize('fact_number, expected', [\n",
    "    (0, 1),\n",
    "    (1, 1),\n",
    "    (2, 2),\n",
    "    (3, 6),\n",
    "    (4, 24),\n",
    "    (5, 120)\n",
    "])\n",
    "def test_methods(fact_number, expected):\n",
    "    assert factorielle(fact_number) == expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.11.6, pytest-7.4.3, pluggy-1.3.0 -- /Users/loic/mambaforge/envs/packaging-2023/bin/python3.11\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/loic/Formations/packaging/practical_session\n",
      "plugins: anyio-4.0.0\n",
      "collected 6 items                                                              \u001b[0m\n",
      "\n",
      "examples/tests/test_parametrize_1.py::test_methods[0-1] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 16%]\u001b[0m\n",
      "examples/tests/test_parametrize_1.py::test_methods[1-1] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 33%]\u001b[0m\n",
      "examples/tests/test_parametrize_1.py::test_methods[2-2] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 50%]\u001b[0m\n",
      "examples/tests/test_parametrize_1.py::test_methods[3-6] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 66%]\u001b[0m\n",
      "examples/tests/test_parametrize_1.py::test_methods[4-24] \u001b[32mPASSED\u001b[0m\u001b[32m          [ 83%]\u001b[0m\n",
      "examples/tests/test_parametrize_1.py::test_methods[5-120] \u001b[32mPASSED\u001b[0m\u001b[32m         [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m6 passed\u001b[0m\u001b[32m in 0.13s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pytest -v examples/tests/test_parametrize_1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting examples/tests/test_parametrize_2.py\n"
     ]
    }
   ],
   "source": [
    "%%file examples/tests/test_parametrize_2.py\n",
    "\n",
    "import pytest\n",
    "\n",
    "from fibonacci import *\n",
    "\n",
    "@pytest.mark.parametrize('value1', range(5))\n",
    "@pytest.mark.parametrize('value2', range(0,10,2))\n",
    "def test_methods(value1, value2):\n",
    "    assert not (value1*value2 & 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.11.6, pytest-7.4.3, pluggy-1.3.0 -- /Users/loic/mambaforge/envs/packaging-2023/bin/python3.11\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/loic/Formations/packaging/practical_session\n",
      "plugins: anyio-4.0.0\n",
      "collected 25 items                                                             \u001b[0m\n",
      "\n",
      "examples/tests/test_parametrize_2.py::test_methods[0-0] \u001b[32mPASSED\u001b[0m\u001b[32m           [  4%]\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[0-1] \u001b[32mPASSED\u001b[0m\u001b[32m           [  8%]\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[0-2] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 12%]\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[0-3] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 16%]\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[0-4] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 20%]\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[2-0] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 24%]\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[2-1] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 28%]\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[2-2] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 32%]\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[2-3] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 36%]\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[2-4] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 40%]\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[4-0] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 44%]\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[4-1] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 48%]\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[4-2] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 52%]\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[4-3] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 56%]\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[4-4] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 60%]\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[6-0] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 64%]\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[6-1] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 68%]\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[6-2] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 72%]\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[6-3] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 76%]\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[6-4] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 80%]\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[8-0] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 84%]\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[8-1] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 88%]\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[8-2] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 92%]\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[8-3] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 96%]\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[8-4] \u001b[32mPASSED\u001b[0m\u001b[32m           [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m25 passed\u001b[0m\u001b[32m in 0.10s\u001b[0m\u001b[32m ==============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pytest -v examples/tests/test_parametrize_2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `approx`\n",
    "\n",
    "Il est souvent utile de comparer les valeurs d'un calcul numérique en s'assurant qu'elles sont proches des valeurs attendues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting examples/tests/test_approx_1.py\n"
     ]
    }
   ],
   "source": [
    "%%file examples/tests/test_approx_1.py\n",
    "\n",
    "from pytest import approx\n",
    "\n",
    "def test_approx_1():\n",
    "    assert 1.001 == approx(1)\n",
    "\n",
    "def test_approx_2():\n",
    "    assert 1.001 == approx(1, rel=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.11.6, pytest-7.4.3, pluggy-1.3.0 -- /Users/loic/mambaforge/envs/packaging-2023/bin/python3.11\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/loic/Formations/packaging/practical_session\n",
      "plugins: anyio-4.0.0\n",
      "collected 2 items                                                              \u001b[0m\n",
      "\n",
      "examples/tests/test_approx_1.py::test_approx_1 \u001b[31mFAILED\u001b[0m\u001b[31m                    [ 50%]\u001b[0m\n",
      "examples/tests/test_approx_1.py::test_approx_2 \u001b[32mPASSED\u001b[0m\u001b[31m                    [100%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m________________________________ test_approx_1 _________________________________\u001b[0m\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_approx_1\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m \u001b[94m1.001\u001b[39;49;00m == approx(\u001b[94m1\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       assert 1.001 == 1 ± 1.0e-06\u001b[0m\n",
      "\u001b[1m\u001b[31mE         comparison failed\u001b[0m\n",
      "\u001b[1m\u001b[31mE         Obtained: 1.001\u001b[0m\n",
      "\u001b[1m\u001b[31mE         Expected: 1 ± 1.0e-06\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mexamples/tests/test_approx_1.py\u001b[0m:5: AssertionError\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m examples/tests/test_approx_1.py::\u001b[1mtest_approx_1\u001b[0m - assert 1.001 == 1 ± 1.0e-06\n",
      "\u001b[31m========================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m1 passed\u001b[0m\u001b[31m in 0.06s\u001b[0m\u001b[31m ==========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pytest -v examples/tests/test_approx_1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting examples/tests/test_approx_2.py\n"
     ]
    }
   ],
   "source": [
    "%%file examples/tests/test_approx_2.py\n",
    "\n",
    "import numpy as np\n",
    "import pytest\n",
    "from pytest import approx\n",
    "\n",
    "def ones_array(shape):\n",
    "    return np.ones(shape)\n",
    "\n",
    "@pytest.fixture(params=[5, (3,2), (5, 4, 3)])\n",
    "def init_array(request):\n",
    "    return ones_array(request.param)\n",
    "\n",
    "def test_approx(init_array):\n",
    "    shape = init_array.shape\n",
    "    random_array = 1 + 1e-5*np.random.random(shape)\n",
    "    assert random_array == approx(init_array, rel=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.11.6, pytest-7.4.3, pluggy-1.3.0 -- /Users/loic/mambaforge/envs/packaging-2023/bin/python3.11\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/loic/Formations/packaging/practical_session\n",
      "plugins: anyio-4.0.0\n",
      "collected 3 items                                                              \u001b[0m\n",
      "\n",
      "examples/tests/test_approx_2.py::test_approx[5] \u001b[32mPASSED\u001b[0m\u001b[32m                   [ 33%]\u001b[0m\n",
      "examples/tests/test_approx_2.py::test_approx[init_array1] \u001b[32mPASSED\u001b[0m\u001b[32m         [ 66%]\u001b[0m\n",
      "examples/tests/test_approx_2.py::test_approx[init_array2] \u001b[32mPASSED\u001b[0m\u001b[32m         [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m3 passed\u001b[0m\u001b[32m in 0.12s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pytest -v examples/tests/test_approx_2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Les `id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting examples/tests/test_approx_id_2.py\n"
     ]
    }
   ],
   "source": [
    "%%file examples/tests/test_approx_id_2.py\n",
    "\n",
    "import numpy as np\n",
    "import pytest\n",
    "from pytest import approx\n",
    "\n",
    "def ones_array(shape):\n",
    "    return np.ones(shape)\n",
    "\n",
    "@pytest.fixture(params=[5, (3,2), (5, 4, 3)],\n",
    "                ids=['1d', '2d', '3d'])\n",
    "def init_array(request):\n",
    "    return ones_array(request.param)\n",
    "\n",
    "def test_approx(init_array):\n",
    "    shape = init_array.shape\n",
    "    random_array = 1 + 1e-5*np.random.random(shape)\n",
    "    assert random_array == approx(init_array, rel=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.11.6, pytest-7.4.3, pluggy-1.3.0 -- /Users/loic/mambaforge/envs/packaging-2023/bin/python3.11\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/loic/Formations/packaging/practical_session\n",
      "plugins: anyio-4.0.0\n",
      "collected 3 items                                                              \u001b[0m\n",
      "\n",
      "examples/tests/test_approx_id_2.py::test_approx[1d] \u001b[32mPASSED\u001b[0m\u001b[32m               [ 33%]\u001b[0m\n",
      "examples/tests/test_approx_id_2.py::test_approx[2d] \u001b[32mPASSED\u001b[0m\u001b[32m               [ 66%]\u001b[0m\n",
      "examples/tests/test_approx_id_2.py::test_approx[3d] \u001b[32mPASSED\u001b[0m\u001b[32m               [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m3 passed\u001b[0m\u001b[32m in 0.08s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pytest -v examples/tests/test_approx_id_2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Utiliser des plugins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Le fichier `conftest.py`\n",
    "\n",
    "- permet de déclarer des fixtures qui pourront être utilisées pour l'ensemble de votre projet\n",
    "- permet de déclarer vos propres plugins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Déclarer une fixture dans `conftest.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting examples/tests/conftest.py\n"
     ]
    }
   ],
   "source": [
    "%%file examples/tests/conftest.py\n",
    "\n",
    "import pytest\n",
    "\n",
    "@pytest.fixture()\n",
    "def hello():\n",
    "    print('Hello !!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting examples/tests/test_conftest_fixture.py\n"
     ]
    }
   ],
   "source": [
    "%%file examples/tests/test_conftest_fixture.py\n",
    "\n",
    "def test_conftest_fixture(hello):\n",
    "    assert True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.11.6, pytest-7.4.3, pluggy-1.3.0 -- /Users/loic/mambaforge/envs/packaging-2023/bin/python3.11\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/loic/Formations/packaging/practical_session\n",
      "plugins: anyio-4.0.0\n",
      "collected 1 item                                                               \u001b[0m\n",
      "\n",
      "examples/tests/test_conftest_fixture.py::test_conftest_fixture Hello !!\n",
      "\u001b[32mPASSED\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.02s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pytest -s -v examples/tests/test_conftest_fixture.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercices\n",
    "\n",
    ":::{exercise}\n",
    "Créez un répertoire `tests`.\n",
    ":::\n",
    "\n",
    ":::{exercise}\n",
    "Créez un environnment `pixi` qui contient `pytest`. \n",
    ":::\n",
    "\n",
    ":::{exercise}\n",
    "Ecrivez deux tests dans `test_shape.py` qui testent si la fonction `circle` fait bien ce qu'il faut. Rappelons que la fonction `circle` prend en paramètres le centre et le rayon ainsi qu'un nombre de point de discrétisation. Par exemple si le centre est $[0, 0]$, le rayon $1$\n",
    "\n",
    "- et le nombre de points $2$, alors le `path` est `[[1, 0], [1, 0]]`, \n",
    "- et le nombre de points $5$, alors le `path` est `[[1, 0], [0, 1], [-1, 0], [0, -1], [1, 0]]`.\n",
    ":::  \n",
    "\n",
    ":::{exercise}\n",
    "Réécrivez ces deux tests en un en utilisant une `fixture` ou un `parametrize`.\n",
    ":::\n",
    "\n",
    ":::{exercise}\n",
    "Testez que la fonction `spline` renvoie bien un vecteur nul si on lui passe une droite. Vous testerez pour différentes droites ayant des caractéristiques différentes.\n",
    ":::\n",
    "\n",
    ":::{exercise}\n",
    "Testez la fonction `splint` en remarquant que calculer les valeurs d'un échantillon qui a servi pour calculer l'équation de la spline fait que l'on trouve à la fin les mêmes coordonnées.\n",
    ":::\n",
    "\n",
    ":::{exercise}\n",
    "Utilisez `pytest-cov` pour tester la couverture de votre projet.\n",
    "\n",
    "```bash\n",
    "pytest --cov nom_du_projet\n",
    "```\n",
    "\n",
    "Comment améliorer la couverture ?\n",
    ":::\n",
    "\n",
    ":::{exercise}\n",
    "Réalisez un test sur le cercle qui compare le résultat à une figure de référence en utilisant le plugin [pytest-mpl](https://github.com/matplotlib/pytest-mpl).\n",
    ":::"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "rise": {
   "autolaunch": true,
   "scroll": true,
   "width": "80%"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
